<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>use.perl.org journal of Ovid: Oh god, please, no.</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="/static/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the
bottom of the topbar */
      }
    </style>
    <link href="/static/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script
src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/static/ico/favicon.ico">
  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse"
data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/"><img src="/static/img/slashhead.png"/></a>
          <div class="nav-collapse">
            <ul class="nav">
              <li><a href="/">Home</a></li>
              <li><a href="/about/">About</a></li>
              <li><a href="/authors/">Authors</a></li>
              <li><a href="/journals/">Journals</a></li>
              <li><a href="/stories/">Stories</a></li>
            </ul>
            <p class="navbar-text">All the Perl that's Practical to Extract and Report</p>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>



<div class="container">

<div class="row">

<div class="span4">
<h1>Oh god, please, no.</h1>
<h2><a href="/user/Ovid/">Ovid</a> on 2008-11-20T16:46:00</h2>
</div> <!-- /span4 -->


<div class="span8">
<p><P>Struggling all day with Gutenberg.  Someone (not naming them as I don't have permission) sent me code to let me use <a href="http://search.cpan.org/user/djbeckett/Redland-1.0.5.4/">Redland</a> for my RDF parsing and it looks lovely.  Too bad <a href="http://www.cpantesters.org/show/Redland.html#Redland-1.0.5.4">Redland doesn't compile for anyone</a>.  Didn't compile for me, either.</p>

<p>I put this aside for a bit and tried parsing result pages.</p>

<p>Tried to use the <a href="http://search.cpan.org/dist/Web-Scraper/">Web::Scraper</a> module to at least pull results from Web pages, but I'm too stupid to figure out its syntax.  Learning a new API, CSS selectors and battling strange "don't know what to do with undef" errors proved too much.  Embarrassing.</p>

<p>I thought to use <a href="http://search.cpan.org/dist/HTML-TableParser/">HTML::TableParser</a> for some stuff, but that doesn't seem to let me at the attributes I need.</p>

<P>I thought XPath would be good, but it's not well-formed XML.  Someone mentioned to me that there might be an XPath module which might have an option which might let you parse malformed XML.  I didn't follow up on that.</p>

<p>I finally switch to my <a href="http://search.cpan.org/dist/HTML-TokeParser-Simple/">HTML::TokeParser::Simple</a> module for this.  It's not a good fit for this problem.  No, scratch that.  It's a bad fit for this problem, but it worked.  Then I turned back to search.  For this, I used <a href="http://search.cpan.org/dist/WWW-Mechanize">WWW::Mechanize</a>.  Notice anything, um, <em>crap</em> about these damned results?</p>

<pre>sub search {  
    my $self = shift;
    my $mech = WWW::Mechanize->new(
        agent     => 'App::Gutenberg (perl)',
        autocheck => 1,       
    );                        
                              
    $mech->get(App::Gutenberg->search_url);

    $mech->submit_form(
        form_number => 1,
        fields      => {
            'author' => ($self->author || ''),
            'title'  => ($self->title  || ''),
        }
    );

    my $uri = $mech->uri;
    if ( $uri =~ /#([[:word:]]+)\z/ ) {
        # you have got to
    }
    else {
        # be kidding me
    }
}</pre>

<p>If that URL matches, you're indexing into a list of &lt;li&gt; elements.  Otherwise, you're parsing a table.  Either way, it's a right pain to get the data you want.  Oh, and it's subtly different sets of data and the criteria for why it would be one type of result or another is unclear.</p>

<p>This is why I want to see REST for just about anything today.  It's simple.  It's straightforward.  It doesn't make me cry.  Now I know why you don't see Perl command line clients for Gutenberg.  Everything I'm writing is so damned fragile it will break if you look at it funny.  *sniff*</p>

<p><strong>Update:</strong>  it looks like any search with an author will return a list, but all other searches (only tested the basic form) return tables.</p></p>


<hr/>



<h2>not XML then?</h2>
<h3><a href="/user/nicholas/">nicholas</a> on 2008-11-20T18:21:46</h3>
<blockquote><div><p>not well-formed XML</p></div></blockquote><p>I thought that there is only well-formed XML. Anything that is not, is simply <b>not</b> XML. The intent being to avoid the tag soup and Do-What-I-Think-You-Meant heuristics that got us to the HTML we have today.</p><p>Hence it sounds like even this so-called "RDF" that they are producing is fundamentally broken, if RDF <b>is</b> XML, and XML <b>is</b> well-formed. Not that this helps you, of course<nobr> <wbr></nobr>:-(</p>



<blockquote>

<h2>Re:not XML then?</h2>
<h3><a href="/user/Ovid/">Ovid</a> on 2008-11-20T18:36:09</h3>
<p>The RDF is well-formed, it's the Web site which is not.  The RDF was very confusing, though, and I simply don't know it well enough to to manually use an XML parser to get all of the data I need.</p>



<blockquote>

<h2>Re:not XML then?</h2>
<h3><a href="/user/Aristotle/">Aristotle</a> on 2008-11-23T20:26:52</h3>
<p>Extracting information from RDF/XML with an XML parser is a fool&#8217;s errand. RDF is a graph model, and RDF/XML is merely one (fairly TMTOWTDI-heavy) representation of it. It is possible to design XML documents so that they can also be parsed as RDF, but if the data was modelled in RDF with no consideration given to the XML parsing case, then trying to parse its RDF/XML representation is likely to produce code more analogous to a regex-based HTML scraper than a parser.</p>





</blockquote>

</blockquote>


<h2>Use whatever parsing engine Web::Scraper uses</h2>
<h3><a href="/user/Corion/">Corion</a> on 2008-11-20T19:16:24</h3>
<p>I've done some work with Web::Scraper, and I found that I mostly give it XPath syntax, which it handles fairly well, even with tagsoup.</p><p>I have <a href="http://datenzoo.de/pub/gpw2008/web-scraper/web-scraper-talk.html" title="datenzoo.de">a talk on Web::Scraper</a datenzoo.de> online, but it's in German. The hilarious <a href="http://66.196.80.202/babelfish/translate_url_content?.intl=de&amp;lp=de_en&amp;trurl=http%3A%2F%2Fdatenzoo.de%2Fpub%2Fgpw2008%2Fweb-scraper%2Fweb-scraper-talk.html" title="66.196.80.202">babelfish translation</a 66.196.80.202> might provide some  shallow entertainment to you though.</p>



<h2>XPath is definitely what you want</h2>
<h3><a href="/user/grantm/">grantm</a> on 2008-11-20T20:07:38</h3>
The LibXML module has a parse_html method that can be used to parse any old crappy HTML.  It does tend to spew warnings to STDERR whether you want them or not but you can localise a redirection of STDERR if you don't want them.



<h2>HTML::TreeBuilder::XPath</h2>
<h3><a href="/user/srezic/">srezic</a> on 2008-11-21T00:14:11</h3>
With HTML::TreeBuilder::XPath you can do xpath-like searches on HTML documents.





</div> <!-- /span8 -->

</div> <!-- row -->
</div> <!-- /container -->



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

  </body>
</html>

