<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>use.perl.org journal of Ovid: Finding Duplicate Files</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="/static/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the
bottom of the topbar */
      }
    </style>
    <link href="/static/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script
src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/static/ico/favicon.ico">
  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse"
data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/"><img src="/static/img/slashhead.png"/></a>
          <div class="nav-collapse">
            <ul class="nav">
              <li><a href="/">Home</a></li>
              <li><a href="/about/">About</a></li>
              <li><a href="/authors/">Authors</a></li>
              <li><a href="/journals/">Journals</a></li>
              <li><a href="/stories/">Stories</a></li>
            </ul>
            <p class="navbar-text">All the Perl that's Practical to Extract and Report</p>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>



<div class="container">

<div class="row">

<div class="span4">
<h1>Finding Duplicate Files</h1>
<h2><a href="/user/Ovid/">Ovid</a> on 2009-10-06T08:52:03</h2>
</div> <!-- /span4 -->


<div class="span8">
<p><P>I'm trying to find files in one directory which are in another directory.  The following works, but I assume there's an easier way?</p>

<pre>for file in `ls aggtests/pips/api/v1/xml/*.t | cut -d/ -f6`; do find aggtests/pips/api/builder/ -name $file; done</pre>

<p>Update: Rewrote to fix a tiny grep bug.</p></p>


<hr/>



<h2>fdupes, File::Find::Duplicate</h2>
<h3><a href="/user/brunov/">brunov</a> on 2009-10-06T10:46:15</h3>
Unless your definition of duplicate files includes files with the same name but possibly different contents, fdupes (available in Ubuntu, for instance) could be what you need. It uses md5sum to identify duplicate files, so it'll even work for identical files with different names.

<p>
A homegrown version can be found here (http://www.perlmonks.org/?node_id=703798), it uses File::Find::Duplicate.</p>



<h2>Lots of hash based solution</h2>
<h3><a href="/user/ajt/">ajt</a> on 2009-10-06T10:51:28</h3>
<p>There are lots of hash based solutions that can do this, some of them are easy written in Perl...</p><p> <a href="http://en.wikipedia.org/wiki/Fdupes" title="wikipedia.org">http://en.wikipedia.org/wiki/Fdupes</a wikipedia.org>, also lists alternatives (including one of mine!).</p>



<h2>uniq</h2>
<h3><a href="/user/mauzo/">mauzo</a> on 2009-10-06T15:19:24</h3>
<blockquote><div><p> <tt>(ls aggtests/pips/api/v1/xml/*.t; ls aggtests/pips/api/builder/*.t) | sort | uniq -d</tt></p></div> </blockquote>



<blockquote>

<h2>Re:uniq</h2>
<h3><a href="/user/merlyn/">merlyn</a> on 2009-10-09T00:00:11</h3>
"ls aggtests/pips/api/v1/xml/*.t"
<p>
"ls... glob" FAIL.  Please don't do that.</p>



<blockquote>

<h2>Re:uniq</h2>
<h3><a href="/user/merlyn/">merlyn</a> on 2009-10-09T00:03:27</h3>
I just realized that message is probably insufficient.  Here's the "dangerous use of ls" message, spelled out a bit better: <a href="http://groups.google.com/group/comp.unix.shell/msg/5d19dadaf9329f87" title="google.com">http://groups.google.com/group/comp.unix.shell/msg/5d19dadaf9329f87</a google.com>



<blockquote>

<h2>Re:uniq</h2>
<h3><a href="/user/mauzo/">mauzo</a> on 2009-10-09T00:33:08</h3>
OK, so had I thought a bit more I might have written<blockquote><div><p> <tt>echo<nobr> <wbr></nobr>.../*.t<nobr> <wbr></nobr>.../*.t | sort | uniq -d</tt></p></div> </blockquote><p>The other point, that filenames can contain special characters, I was aware of, but I tend to assume that 'my' files won't (unless I know that they do). If I were working on some arbitrary set of files I would have done the job in Perl (I was going to say <code>find -print0</code> and <code>{sort,uniq} -z</code> would work, but apparently (my) <code>uniq</code> doesn't have a <code>-z</code> option. Weird.). Thanks for the correction, though, since it's important to be aware of in general.
</p><p>A more important bug I was also ignoring is that the length of the list of files may exceed <code>ARG_MAX</code>. Since this is one of Ovid's test directories, I presume that's not actually that unlikely<nobr> <wbr></nobr><code>:)</code>.</p>



<blockquote>

<h2>Re:uniq</h2>
<h3><a href="/user/Aristotle/">Aristotle</a> on 2009-10-09T14:07:28</h3>
<blockquote><div><blockquote><div><p> <tt> echo<nobr> <wbr></nobr>.../*.t<nobr> <wbr></nobr>.../*.t | sort | uniq -d</tt></p></div> </blockquote></div> </blockquote><p>That won&#8217;t do what you wanted because <code>echo</code> will output the whole shebang on a single line. What you want instead is</p><blockquote><div><p> <tt>printf '%s\n'<nobr> <wbr></nobr>.../*.t<nobr> <wbr></nobr>.../*.t | sort | uniq -d</tt></p></div> </blockquote><p>But then that still won&#8217;t do what you wanted, because you aren&#8217;t chopping the base path off the file names, so no two lines will have the same content anyway. You need to something like this:</p><blockquote><div><p> <tt>printf '%s\n'<nobr> <wbr></nobr>.../*.t<nobr> <wbr></nobr>.../*.t | cut -d/ -f2- | sort | uniq -d</tt></p></div> </blockquote><p>Of course, as mentioned, that doesn&#8217;t account for the possibility of newlines in file names. And trying to do so is awkward since not all Unix utilities have switches to enable null- rather than newline-terminated records, <code>uniq</code> and <code>cut</code> among them.</p>





</blockquote>

</blockquote>

</blockquote>

</blockquote>


<h2>I'd just...</h2>
<h3><a href="/user/AndyArmstrong/">AndyArmstrong</a> on 2009-10-06T18:01:24</h3>
...do a find in each directory and then diff the results.<br/><br/>cd firstdir &amp;&amp; find . -type f &gt; ~/first
cd seconddir &amp;&amp; find . -type f &gt; ~/second
cd ~ &amp;&amp; diff first second<br/><br/>You can filter the output of the diff of course<nobr> <wbr></nobr>:)





</div> <!-- /span8 -->

</div> <!-- row -->
</div> <!-- /container -->



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

  </body>
</html>

