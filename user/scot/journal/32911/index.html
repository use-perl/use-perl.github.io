<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>use.perl.org journal of scot: Method for extracting urls for filetypes + auto-retrieval</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="/static/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the
bottom of the topbar */
      }
    </style>
    <link href="/static/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script
src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/static/ico/favicon.ico">
  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse"
data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/"><img src="/static/img/slashhead.png"/></a>
          <div class="nav-collapse">
            <ul class="nav">
              <li><a href="/">Home</a></li>
              <li><a href="/about/">About</a></li>
              <li><a href="/authors/">Authors</a></li>
              <li><a href="/journals/">Journals</a></li>
              <li><a href="/stories/">Stories</a></li>
            </ul>
            <p class="navbar-text">All the Perl that's Practical to Extract and Report</p>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>



<div class="container">

<div class="row">

<div class="span4">
<h1>Method for extracting urls for filetypes + auto-retrieval</h1>
<h2><a href="/user/scot/">scot</a> on 2007-04-04T22:51:12</h2>
</div> <!-- /span4 -->


<div class="span8">
<p><p><a href="http://perlmonks.org/?node_id=559293">This post</a> reminded me of a problem which I have been trying to solve involving extracting URL's pointing to a specific filetype (say a gz archive) from a web page. It turns out that at <a href="http://cpan.org/">CPAN</a> there is a <a href="http://cpan.org/modules/01modules.index.html">page </a>which contains an alphabetical list of all modules, with a hyperlink to the tar.gz file of each module.</p>

<p>The following code (given appropriate substitution of the command line input; ie gz for pdf) will create a text file with all of the URL's for the tar.gz files:</p>
<pre>
use strict;
use LWP::Simple;
use HTML::SimpleLinkExtor;
#usage getfileoftype http://www.example.com pdf > urllist.txt
my $url = shift;
my $filetype = shift;
my $filetypelen = length($filetype);
my $offset = -$filetypelen;
#print $filetypelen."\n";
#print $offset."\n";
my $fileget = getstore($url,"tempfile.html");
my $extor = HTML::SimpleLinkExtor->new(); $extor->parse_file("tempfile.html");
my @a_hrefs = $extor->a;
for my $element (@a_hrefs) { 
# print $element;
# print "\n";
my $suffix = substr($element,$offset,$filetypelen);
# print $suffix;
# print "\n"; if ($suffix =~ m/$filetype/){
print $element;
print "\n";
}
}
</pre>

<p>Once you have that, you can then use the following code to automatically download all of the modules if you so choose, or whatever subset of the modules you wish to extract from the text file created by the above code:</p>
<pre>
use strict;
use LWP::Simple;
use File::Basename;
open (DATA, "urllist.txt") || die "File open failure!";
while (my $downloadurl = <DATA>){
(my $name, my $path, my $suffix) = fileparse($downloadurl);
my $finurl = $downloadurl;
print $finurl."\n";
my $savefilename = $name.$suffix;
print $savefilename;
print "\n";
my $status = getstore($finurl,$savefilename); print $status."\n"
}
</pre>
<p>Both pieces of code work nicely on my WinXP box. Yes, I know that "tempfile.html" gets clobbered, but I was just glad to get this code working, and WinXP doesn't seem to care. In any case, one can now generate a local repository of modules. Suggestions for improvement in my code are welcome!</p>

</p>


<hr/>



<h2>CPAN::Mini</h2>
<h3><a href="/user/jdavidb/">jdavidb</a> on 2007-04-04T23:18:52</h3>
<p>Have you seen <a href="http://www.stonehenge.com/merlyn/LinuxMag/col42.html" title="stonehenge.com">this</a stonehenge.com> and <a href="http://search.cpan.org/user/rjbs/CPAN-Mini-0.552/lib/CPAN/Mini.pm" title="cpan.org">this</a cpan.org>?</p>



<blockquote>

<h2>Re:CPAN::Mini</h2>
<h3><a href="/user/scot/">scot</a> on 2007-04-05T13:42:15</h3>
<p>I had looked at the CPAN::Mini module but didn't notice the link to the article.  My objective with the code was to allow me to use it for extracting files from any web page, not just CPAN.  For example, occasionally I'll do a Google search for pdf documents on a particular subject. Now I can save the search page; use the first script to get the pdf links, and use the second to quickly download them all.</p>

No doubt somewhere someone has produced similar code but I learned a lot writing these scripts in any case.  Thanks for the feedback...





</div> <!-- /span8 -->

</div> <!-- row -->
</div> <!-- /container -->



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

  </body>
</html>

