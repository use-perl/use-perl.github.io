<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>use.perl.org journal of ziggy: Why Turing?</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="/static/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the
bottom of the topbar */
      }
    </style>
    <link href="/static/css/bootstrap-responsive.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script
src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="/static/ico/favicon.ico">
  </head>

  <body>

    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="btn btn-navbar" data-toggle="collapse"
data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="/"><img src="/static/img/slashhead.png"/></a>
          <div class="nav-collapse">
            <ul class="nav">
              <li><a href="/">Home</a></li>
              <li><a href="/about/">About</a></li>
              <li><a href="/authors/">Authors</a></li>
              <li><a href="/journals/">Journals</a></li>
              <li><a href="/stories/">Stories</a></li>
            </ul>
            <p class="navbar-text">All the Perl that's Practical to Extract and Report</p>
          </div><!--/.nav-collapse -->
        </div>
      </div>
    </div>



<div class="container">

<div class="row">

<div class="span4">
<h1>Why Turing?</h1>
<h2><a href="/user/ziggy/">ziggy</a> on 2002-03-06T23:37:28</h2>
</div> <!-- /span4 -->


<div class="span8">
<p>Last night, <a href="http://www.nasm.si.edu/nasm/dsh/nasem001.html">Paul Ceruzzi</a> came to talk to the DC Perl Mongers.  His topic, appropriately enough, was the history of computing.  (His book, <i><a href="http://mitpress.mit.edu/book-home.tcl?isbn=0262032554">A History of Modern Computing</a></i> is about to be updated with a second edition, covering important events through 2001.)
<p>
Towards the end of the evening, one of the people in the group asked why computing didn't start <i>before</i> the 1940's.  After all, Charles Babbage was doing his work in the 1850's, and Herman Hollerith had automated the 1890 census with punched cards.  So why didn't computing take off until Alan Turing entered the scene?
<p>
It turns out the answer is quite interesting, and sheds light on just how profound Turing's contributions to society were.  First, prior to Turing, innovations in the realm of calculating machines were focused on creating ways to alleviate the tedium of calculation.  Babbage used clockwork to compute numbers accurately, and Hollerith used plug boards to automate sorting and counting.  Both of these gentlemen were focused on a base-10 representation of the world.  Both focused on creating machines that could be configured at the start of a computation (turning the columns in Babbage's case, wiring the plugboard in Hollerith's case) thereby allowing the machines to  run until completion.
<p>
In the early 20th Century, electronic switches and vacuum tubes entered the scene.  However, those who were tinkering with computing in some way shape or form were laboring under the paradigm that "computing machines" were devices that were configurable at setup time and dealt with base-10 values.
<p>
This is still true through the end of WWII.  I forget what Konrad Zuse was doing, but I'm pretty sure he hadn't hit upon the concept of a stored program architecture.  Presper Eckert and John Maunchley were using vacuum tubes and other electronic switching devices to ferry base-10 values around ENIAC (which was "programmed" by connecting switches at the start of a computation).  Most of the Harvard Mark I was on hold during the war, but I recall that it too worked on a configurable start state concept to shove around base-10 values (for creating tables of Bessel Functions; when was the last time you needed to refer to one of those?).
<p>
&nbsp;
<p>
So, what did Turing do that changed the world?  First off, Alan Turing linked together a couple of seemingly unrelated chains of thought, and added a few of his own.  First, he gave meaning to the seemingly meaningless base-2 arithmetic, allowing engineers to do interesting things with electronic switches and relays (thus simplifying the design and development of computing hardware).  Secondly, he introduced the concept of a <b>stored program</b> that sat in the computer's memory.  All of a sudden, computers became much more malleable, since it would now be possible to save state and restore it without spending hours plugging wires into plugboards just to start a long summation, integration or tabulation.
<p>
But you probably knew all that already.  :-)</p>


<hr/>



<h2>Konrad Zuse ...</h2>
<h3><a href="/user/jand/">jand</a> on 2002-03-07T04:59:31</h3>
claimed he already knew about "program memory" in 1939, but said it wasn't practical yet:<br> <br> <blockquote><div> <i>The question is why I did not use this concept in 1939 if I already knew about it. Well, at that time it would have been senseless to try to build that sort of machine, as the necessary facilities were simply not available. For example, storage capacity was not big enough to cope - an efficient program memory needs to be able to store several thousand words.</i> </div></blockquote> <br> <p>From: <a href="http://ei.cs.vt.edu/user/history/Zuse.html" title="vt.edu">Konrad Zuse</a vt.edu>, actually, from the <a href="http://ei.cs.vt.edu/user/history/Zuse.2.html" title="vt.edu">second page</a vt.edu>.</p>



<h2>It's weird isn't it?</h2>
<h3><a href="/user/pdcawley/">pdcawley</a> on 2002-03-07T09:22:21</h3>
The very thing that makes Turing type machines so powerful (the blurring of the line between code and data) is, in a sense the very thing we often try to avoid as programmers. Self-modifying code is considered harmful and generally mind bending, so we don't do it.



<blockquote>

<h2>Re:It's weird isn't it?</h2>
<h3><a href="/user/chaoticset/">chaoticset</a> on 2002-03-07T19:25:13</h3>
Speaking of self-modifying code, <a href="http://www.mines.edu/students/b/bolmstea/malbolge/" title="mines.edu">Malbolge</a mines.edu> is an <a href="http://www.andrewcooke.free-online.co.uk/andrew/writing/malbolge.html" title="free-online.co.uk">interestingly</a free-online.co.uk> <a href="http://www2.latech.edu/user/acm/helloworld/malbolge.html" title="latech.edu">bizarre</a latech.edu> language, courtesy of Ben Olmstead.





</div> <!-- /span8 -->

</div> <!-- row -->
</div> <!-- /container -->



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

  </body>
</html>

